Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.1Lecture 6
Machine Learning for Intelligent Systems
Introduction, Clustering, ClassiÔ¨Åcation, Regression, Evaluation
COMP 474/6741, Winter 2024
Ren√© Witte
Department of Computer Science
and Software Engineering
Concordia University
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.2Outline
1Machine Learning Primer
History
ML Types
Process
2Clustering Documents
Motivation
k-Means Clustering
Application Example
3ClassiÔ¨Åcations & Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
4Machine Learning Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
5Notes and Further Reading
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.3AI, ML, DL
https://medium.com/machine-learning-for-humans/neural-networks-deep-learning-cdad8aeae49b
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.4History
Learn from experience
In 1959, Arthur Samuel Ô¨Årst proposed the concept
Machine Learning:
‚ÄúA computer program is said to learn from expe-
rience E with respect to some class of tasks T
and performance measure P if its performance at
tasks in T, as measured by P , improves with expe-
rience E.‚Äù

Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.5Automated Reasoning
Inference
Process of deriving new facts from a set of premises
Types of logical inference
1Deduction
2Abduction
3Induction
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.6Deduction
aka Natural Deduction
Conclusion follows necessary from the premises.
From A)B and A, we conclude that B
We conclude from the general case to a speciÔ¨Åc example of the general case
Example:
1All men are mortal.
2Socrates is a man.
3from 1^2)Socrates is mortal.
Our subclass inference in RDFS also falls into this category.
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.7Abduction
Abductive Reasoning
Conclusion is one hypothetical (most probable) explanation for the premises
From A)B and B, we conclude A
Example:
1Drunk people do not walk straight.
2John does not walk straight.
3from 1^2)John is drunk.
Not sound. . . but may be most likely explanation for B
Used in medicine. . .
1in reality: disease )symptoms
2patient complains about some symptoms. . . doctor concludes a disease
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.8Induction
Inductive Reasoning
Conclusion about all members of a class from the examination of only a few
member of the class.
From A^C)B and A^D)B, we conclude A )B
We construct a general explanation based on speciÔ¨Åc cases
Example:
1All CS students in COMP 474 are smart.
2All CS students on vacation are smart.
3from 1^2)All CS students are smart.
Not sound
But, can be seen as hypothesis construction or generalisation
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.9Inductive Learning
Learning from examples
Most work in ML
Examples are given (positive and/or negative) to train a system in a
classiÔ¨Åcation (or regression) task
Extrapolate from the training set to make accurate predictions about future
examples
Given a new instance X you have never seen, you must Ô¨Ånd an estimate of the
function f(X) where f(X) is the desired output
From datascience.com, https://towardsdatascience.com/cat- dog- or- elon- musk- 145658489730
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.10Example
Given pairs (X;f(X))(the training set ‚Äì the data points)
Find a function fthat Ô¨Åts the training set well
So that given a new X, you can predict its f(X)value
Note: choosing one function over another beyond just looking at the training set is
called inductive bias (eg. prefer ‚Äúsmoother‚Äù functions)
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.11Inductive Learning Framework
Feature Vectors
Input data are represented by a vector of features, X
Each vector Xis a list of (attribute, value) pairs.
Ex:X=[nose:big, teeth:big, eyes:big, moustache:no]
The number of attributes is Ô¨Åxed (positive, Ô¨Ånite)
Each attribute has a Ô¨Åxed, Ô¨Ånite number of possible values
Each example can be interpreted as a point in a n-dimensional feature space,
where nis the number of attributes (features)
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.12Some Machine Learning Techniques
Probabilistic Methods
e.g., Na√Øve Bayes ClassiÔ¨Åer
Decision Trees
Use only discriminating features as questions in a big if-then-else tree
Neural Networks
Also called parallel distributed processing or connectionist systems
Intelligence arise from having a large number of simple computational units
NB: Deep Learning Neural Networks ‚Äúon steroids‚Äù
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.13Supervised Learning
Labeled Data
In Supervised Learning, we train a system using data with known labels.
EDA =Exploratory Data Analysis, see https://towardsdatascience.com/exploratory-data-analysis-8fc1cb20fd15
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.14Unsupervised Learning
Unlabeled Data
In Unsupervised Learning, we have only unlabeled data and train a system without
guidance from an expected output.
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.15Reinforcement Learning
Feedback and Rewards
In Reinforcement Learning, an agent learns to make decisions by performing
actions and receiving feedback in the form of rewards or penalties, optimizing its
behavior towards long-term objectives.
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.16AI Learns to Park
https://www.youtube.com/watch?v=VMp6pq6_QjI
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.17Machine Learning Categories

Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.18
http://www.cognub.com/index.php/cognitive-platform/
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.19General machine learning process
!Work sheet #5:Task 1
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.20Outline
1Machine Learning Primer
2Clustering Documents
Motivation
k-Means Clustering
Application Example
3ClassiÔ¨Åcations & Predictions
4Machine Learning Evaluation
5Notes and Further Reading
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.21Math with Words
Vector Space Model
A mathematical model to portray an n-dimensional space
Entities are described by vectors with ncoordinates in a real space Rn
Given two vectors, we can compute a similarity coefÔ¨Åcient between them
Cosine of the angle between two vectors reÔ¨Çects their degree of similarity
tf=1+ log( tft;d) (1)
idf= logN
dft(2)
cos(~q;~d) =Pjvj
i=1qidiqPjvj
i=1qi2qPjvj
i=1di2(3)

Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.22Motivation
Intelligent Systems for Investigative Journalism
Organize large, unstructured document collections:
Enron email dataset ‚Äì ca. 500,000 emails from management
Wikileaks ‚Äì often releases millions of documents
Guantanamo Bay Files, TPP Agreements, CIA Documents, German BND-NSA
Inquiry, . . .
Facebook internal documents leaks (Cambridge Analytica scandal, 7000
documents)
Luanda Leaks (715,000 emails, charts, contracts, audits, etc.)
Paradise Papers (13.4 million conÔ¨Ådential papers regarding offshore
investments)
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.23
https://www.thestar.com/news/paradise-papers/2019/01/29/canada-revenue-agency-launches-100-audits-after-parad
ise-papers-leak.html
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.24
https://opensemanticsearch.org
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.25Clustering
Unsupervised Learning
Remember, we do not ‚Äúclassify‚Äù documents (like in ‚Äúspam vs. ham‚Äù)
Rather, we group similar documents together
Often used as a Ô¨Årst exploratory step in data analysis
Data points (here: documents) in individual clusters can be further analyzed,
possibly with different methods

Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.26What are Clusters?
Clustering
The organization of unlabeled data into similarity groups, called clusters
A cluster is a collection of data items which are ‚Äúsimilar‚Äù between them, and
‚Äúdissimilar‚Äù to data items in other clusters.
Generally, there is no right or wrong answer to what the clusters in a dataset
are.

Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.27Clustering Techniques

Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.28k-Means Clustering
Partition-based Clustering
K-means (MacQueen, 1967) is a partitional clustering algorithm:
Given mvectors in an n-dimensional space, ~x1; : : : ; ~xm2Rn
User deÔ¨Ånes k, the number of clusters
Algorithm
1Pick kpoints from the dataset (usually at random).
These points represent our initial group centro√Øds.
2Assign each data point ~xito the nearest centro√Ød.
3When all data points have been assigned, recalculate the positions of the k
centro√Øds as the average of the cluster.
4Repeat Steps 2 and 3 until none of the data instances change group
(or changes stay below a given convergence limit ).
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.29Euclidian Distance
To Ô¨Ånd the nearest centro√Ød:
a possible metric is the
Euclidean distance
distance dbetween 2 points p,q
p= (p1;p2; : : : ; pn)
q= (q1;q2; : : : ; qn)
d=vuutnX
i=1(pi qi)2
where to assign a data point ~x?
!for all kclusters, choose the one
where ~xhas the smallest distance

Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.30Example (1/5)
2D-vectors, k=3: Initialize random centro√Øds

Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.31Example (2/5)
Partition data points to closest centro√Øds

Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.32Example (3/5)
Compute new centro√Øds

Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.33Example (4/5)
Re-assign data points to closest new centro√Øds

Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.34Example (5/5)
Repeat until clusters stabilize

Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.35k-Means Clustering Illustrated
https://www.youtube.com/watch?v=5I3Ei69I40s
!Work sheet #5:Task 2
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.36k-Means: Pros & Cons
Pros
Simple, easy to understand and implement
Converges very fast
EfÔ¨Åcient: Time complexity O(tkn), with
nnumber of data points
knumber of clusters
tnumber of iterations
!considered linear for practical purposes
Cons
User needs to choose k(usually not known)
Sensitive to outliers
Different results on same dataset, based on initial (random) centro√Øds
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.37k-Means & Outliers

Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.38k-Means: Sensitivity to Initial Seeds

Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.39k-Means
Summary
Despite weaknesses, k-means is still one of the most popular algorithms, due
to its simplicity and efÔ¨Åciency
No clear evidence that any other clustering algorithm performs better in general
Comparing different clustering algorithms is a difÔ¨Åcult task:
No one knows the correct clusters!

Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.40Document Clustering Example: Analyzing NSF Research Grants
https://www.youtube.com/watch?v=85fZcK5EpnA
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.41Outline
1Machine Learning Primer
2Clustering Documents
3ClassiÔ¨Åcations & Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
4Machine Learning Evaluation
5Notes and Further Reading
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.42ClassiÔ¨Åcation of Data

Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.43ClassiÔ¨Åcation Algorithms

Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.44k-Nearest-Neighbor (kNN) ClassiÔ¨Åcation
kNN Algorithm
Training: only store feature vectors + class labels
Testing: Find the kdata points nearest (e.g., Euclidian distance) to the new
value. Resulting class is decided by majority vote.
Note: in this simple form, kNN has no training effort, but large testing effort
(so-called lazy learning)
Copyright Antti Ajanki (https://commons.wikimedia.org/wiki/File:KnnClassification.svg), ‚ÄúKnnClassiÔ¨Åcation‚Äù,
licensed under https://creativecommons.org/licenses/by- sa/3.0/legalcode
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.45kNN ClassiÔ¨Åcation
With k=1
Compute the distance of the unknown sample to all existing samples
Assign the class of the closest neighbor to the new sample
Distance can be computed with different metrics, e.g.,
Euclidean distance or Manhattan distance
Copyright 2017 by O‚ÄôReilly Media, Inc., [MG17]
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.46kNN ClassiÔ¨Åcation: General case
With arbitrary k
kNN classiÔ¨Åcation becomes a voting algorithm
assign the same class as the majority of the kclosest neighbors to the new
sample
Choice of kis dependent on data set
Copyright 2017 by O‚ÄôReilly Media, Inc., [MG17]
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.47NetÔ¨Çix: Predict Success of Original Content
In 2013, NetÔ¨Çix decided to commission two seasons of the U.S. remake of the
British series House of Cards based on an analysis of its customers‚Äô data
https://informationstrategyrsm.wordpress.com/2014/10/19/big-data-analytics-house-of-cards-and-future-of-television-c
reation-consumption/
!Work sheet #5:Task 3
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.48Regression
Forecasting or predicting a value: e.g., house price, movie rating, temperature at noon, ...
http://www.cognub.com/index.php/cognitive-platform/
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.49kNN Regression
With k=1
Find the nearest existing data point to a new sample as before
Assign the value of this point (e.g., price, rating, ... ) to the new instance
Note: given n-dimensional vectors, we are using n 1 dimensions for the similarity
and the Ô¨Ånal for the predicted value
Copyright 2017 by O‚ÄôReilly Media, Inc., [MG17]
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.50kNN Regression: General Case
Find the knearest existing data points
Assign the average of their values to the new point
Note that this algorithm cannot extrapolate
Copyright 2017 by O‚ÄôReilly Media, Inc., [MG17]
!Work sheet #5:Task 4
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.51Machine Learning at NetÔ¨Çix
https://www.youtube.com/watch?v=X9ZES-fsxgU
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.52Outline
1Machine Learning Primer
2Clustering Documents
3ClassiÔ¨Åcations & Predictions
4Machine Learning Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
5Notes and Further Reading
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.53Evaluation of a ML Model
Methodology
How do you know if what you learned is correct?
Y ou run your classiÔ¨Åer on a data set of unseen examples (that you did not use
for training) for which you know the correct classiÔ¨Åcation (‚Äúgold standard‚Äù)
Training vs. testing data
Split data into training (80%) and testing (20%) sets
Depending on the ML algorithm, the training set can be further split into:
Actual training set (80%)
Validation set (20%)
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.54Standard Methodology
1Collect a large set of examples (all with correct classiÔ¨Åcations)
2Divide collection into training, validation and test set
3Apply learning algorithm to training set to learn the parameters
4Measure performance with the validation set, and adjust hyper-parameters to
improve performance
5Performance not good enough? )3
6Measure performance with the test set
DO NOT LOOK AT THE TEST SET
until you arrived at Step 6.
Parameters
Basic values learned by the ML
model from data, e.g.:
for NB: prior & conditional
probabilities
for k-Means: centroids, cluster
assignments
for ANNs: weightsHyper-Parameters
Parameters used to set up the ML
model, e.g.:
for NB: value of delta for
smoothing
for kNN: value of k
for ANNs: # of hidden layers,
# of nodes per layer. . .
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.55Metrics
Accuracy
% of instances of the test set the algorithm correctly classiÔ¨Åes
when all classes are equally important and represented
Recall & Precision
when one class is more important than the others
F-Measure
Combined Precision & Recall (harmonic mean)
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.56ML Evaluation
Evaluation of ClassiÔ¨Åers
What kind of errors can we make?
Reality says. . .
Positive Negative
Model predicts. . .Positive True Positive (TP) False Positive (FP)
Negative False Negative (FN) True Negative (TN)
This is a so-called (binary) confusion matrix
Error Types
False positive classiÔ¨Åcation: Type I error
(‚Äúconvict the innocent!‚Äù )
False negative classiÔ¨Åcation: Type II error
(‚Äúfree the guilty!‚Äù )
Important realization: not all errors are created equal!
Voltaire: ‚ÄúIt is better to risk saving a guilty man than to condemn an innocent one.‚Äù
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.57Evaluation Metrics
Commonly used
Accuracy = (TP+TN)=(TP+TN+FP+FN)
Recall =TP=(TP+FN)
Precision =TP=(TP+FP)
F1-score =2Precision Recall
Precision +Recall(harmonic mean)
Mind the evaluation task
Precision, recall etc. are deÔ¨Åned slightly differently
for:
Information retrieval tasks
ClassiÔ¨Åcation tasks
Ranked retrieval tasks
Information extraction tasks
!Work sheet #5:Task 5
Copyright by Walber (https://commons.wikimedia.org/wiki/File:Precisionrecall.svg), licensed under the Creative
Commons Attribution-Share Alike 4.0 International license
https://creativecommons.org/licenses/by- sa/4.0/legalcode
!Work sheet #5:Task 5
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.58Confusion Matrix
Where did the learner go wrong ?
Use a confusion matrix (contingency table)

Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.59Learning Curve
Copyright 2007‚Äì2019, scikit-learn developers (BSD License), https://scikit- learn.org/stable/auto_examples/model_selection/plot_learning_curve.html
Plot evaluation metric vs. size of training set
the more, the better
but after a while, not much improvement. . .
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.60Some Words on Training. . .
Watch out for:
Noisy Data
OverÔ¨Åtting
UnderÔ¨Åtting
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.61Noisy Data
Common issues
Two examples have the same feature-value pairs, but different outputs
Some values of features are incorrect or missing (e.g., errors in the data
acquisition)
Some relevant attributes are not taken into account in the data set

Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.62OverÔ¨Åtting
If a large number of irrelevant
features are there, we may Ô¨Ånd
meaningless regularities in the data
that are particular to the training data
but irrelevant to the problem.
Complicated boundaries overÔ¨Åt the
data (a.k.a. overtraining )
they are too tuned to the particular
training data at hand
They do not generalize well to the
new data
Extreme case: ‚Äúrote learning‚Äù
Training error is low
Testing error is high
Copyright by Chabacano (https://commons.wikimedia.org/wiki/File:OverÔ¨Åtting.svg) license under the Creative Commons Attribution-Share
Alike 4.0 International license, https://creativecommons.org/licenses/by- sa/4.0/legalcode
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.63UnderÔ¨Åtting
We can also underÔ¨Åt data, i.e. use
too simple decision boundary
Model is not expressive enough (not
enough features)
a.k.a. Undertraining
There is no way to Ô¨Åt a linear
decision boundary so that the
training examples are well separated
Training error is high
Testing error is high

Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.64Example: Animal ClassiÔ¨Åcation
Features
What about cat vs. dog?
[from: Alison Cawsey: The Essence of AI (1997)]
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.65Cross-Validation
k-fold Cross-Validation
‚ÄòRe-use‚Äô different parts of the training data for testing. E.g., 10-fold cross-validation:
split data into 10 equal parts (optionally, randomly shufÔ¨Çe before)
train on 9 of these, test on the 10th
repeat 10 times, resulting in 10 different performance results
average these for overall performance
Balancing Data Use and Model Validation
Maximizes data use‚Äîevery data point serves in both training ( k 1 times) and
testing (exactly once)
Reduces risk of model overÔ¨Åtting by validating against multiple data subsets
More robust performance estimate by averaging results across multiple splits
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.66Outline
1Machine Learning Primer
2Clustering Documents
3ClassiÔ¨Åcations & Predictions
4Machine Learning Evaluation
5Notes and Further Reading
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.67Reading Material
Required
[MG17, Chapters 2, 3, 5] (kNN, k-Means, Evaluation)
Supplemental
[PS12, Chapter 7] (ML Training)
[PS12, Chapter 8] (Testing and Evaluation)
Ren√© Witte
Machine Learning
Primer
History
ML Types
Process
Clustering Documents
Motivation
k-Means Clustering
Application Example
ClassiÔ¨Åcations &
Predictions
Introduction
ClassiÔ¨Åcation with kNN
Regression with kNN
Machine Learning
Evaluation
Evaluation Methodology
Evaluation Metrics
Error Analysis
OverÔ¨Åtting
UnderÔ¨Åtting
Cross-Validation
Notes and Further
Reading
6.68References
[MG17] Andreas C M√ºller and Sarah Guido.
Introduction to Machine Learning with Python .
O‚ÄôReilly, 2017.
https://concordiauniversity.on.worldcat.org/oclc/960211579.
[PS12] James Pustejovsky and Amber Stubbs.
Natural Language Annotation for Machine Learning .
O‚ÄôReilly, 2012.
https://concordiauniversity.on.worldcat.org/oclc/801812987.